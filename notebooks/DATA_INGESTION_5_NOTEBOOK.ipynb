{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "qw2evqcj5gexuj374dn5",
   "authorId": "1011012698186",
   "authorName": "BHARRIS",
   "authorEmail": "bradley.harris@snowflake.com",
   "sessionId": "d928e847-28de-4a24-b966-8c82d9d9a1ee",
   "lastEditTime": 1738353291050
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "## File Upload & Copy (Serverless) from the Python Connector\n\nIt can be useful to leverage a Serverless Task which is scheduled every minute to ingest the files uploaded by clients over the last minute.\n\nThis has several advantages over using Snowpipe for Copy:\n\n* Eliminates the per file costs incurred by Snowpipe.\n* Small files can be merged together more efficiently\n\nIt is also billed per second of compute so warehouse planning/optimization is not required.\n"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "-- create the table and task needed for this ingest pattern\n\nUSE ROLE ACCOUNTADMIN;\nGRANT EXECUTE TASK ON ACCOUNT TO ROLE INGEST;\nGRANT EXECUTE MANAGED TASK ON ACCOUNT TO ROLE INGEST;\n\nUSE ROLE INGEST;\n\nuse database INGEST;\nuse schema INGEST;\n\nCREATE OR REPLACE TABLE LIFT_TICKETS_PY_SERVERLESS (TXID varchar(255), RFID varchar(255), RESORT varchar(255), PURCHASE_TIME datetime, EXPIRATION_TIME date, DAYS number, NAME varchar(255), ADDRESS variant, PHONE varchar(255), EMAIL varchar(255), EMERGENCY_CONTACT variant);\n\nCREATE OR REPLACE TASK LIFT_TICKETS_PY_SERVERLESS \nUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL' \nAS\nCOPY INTO LIFT_TICKETS_PY_SERVERLESS\nFILE_FORMAT=(TYPE='PARQUET') \nMATCH_BY_COLUMN_NAME=CASE_SENSITIVE \nPURGE=TRUE;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "eee11365-3b77-413a-b4cd-447c99b0124e",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "And we'll use our py_serverless.py for this.\n\nTo test this insert, run the following\n\n```\npython ./data_generator.py 1 | python py_serverless.py 1\n```"
  },
  {
   "cell_type": "code",
   "id": "5fb3475f-eee5-4e47-8a0f-57676436c979",
   "metadata": {
    "language": "sql",
    "name": "cell5"
   },
   "outputs": [],
   "source": "-- Query the table to verify the data was inserted.\n\nSELECT count(*) FROM LIFT_TICKETS_PY_SERVERLESS;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4695dc30-618e-46f9-871b-e3c71ad2bc57",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "To send in all your test data, you can run the following in your shell:\n\n```\ncat data.json.gz | zcat | python py_serverless.py 10000\n```\n\nIf you run multiple tests with different batch sizes (especially smaller sizes), you will see this can save credit consumption over the previous Snowpipe solution as it combines files into loads.\n\nThe code is calling execute task after each file is uploaded. While this may not seem optimimal, it is not running after each file is uploaded. It is leveraging a feature of tasks which does not allow additional tasks to be enqueued when one is already enqueued to run.\n\nIt is also common to schedule the task to run every n minutes instead of calling from the clients."
  },
  {
   "cell_type": "code",
   "id": "dd64113c-b407-4585-86f8-50db2a176135",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": "-- Query the table to verify the data was inserted.\n\nSELECT count(*) FROM LIFT_TICKETS_PY_SERVERLESS;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "### Tips\n* Only run the Task as needed when enough data (> 100mb) has been loaded into stage for most efficiency.\n* Use Serverless Tasks to avoid per file charges and resolve small file inefficiencies."
  }
 ]
}