{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "thlu7osj522chydyyo7f",
   "authorId": "394090024763",
   "authorName": "BHARRIS_DEMO",
   "authorEmail": "bradley.harris@snowflake.com",
   "sessionId": "70852e15-fd60-4ee9-819b-2a4eba14ef20",
   "lastEditTime": 1738961086900
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# LLM FINE TUNING \n\nhttps://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-finetuning\n\nFine-tuning is available to paid accounts in the same regions as Cortex Search, namely:\n\n* AWS US West 2 (Oregon)\n\n* AWS US East 1 (N. Virginia)\n\n* AWS Europe Central 1 (Frankfurt)\n\n* Azure East US 2 (Virginia)\n\nSupport for inference of fine-tuned models is available to accounts in regions that support the COMPLETE function for the base model. For details, see Availability.\n\n## Fine-tuning is not available to trial accounts."
  },
  {
   "cell_type": "markdown",
   "id": "cb071855-180b-4f96-af9c-f148ffeb890d",
   "metadata": {
    "name": "cell24",
    "collapsed": false
   },
   "source": "### Overview\n\nTasty Bytes is a fictional global food truck enterprise that has established its presence in 30 cities spanning across 15 countries, boasting a network of 450 trucks offering 15 diverse menu types under various brands. Our mission at Tasty Bytes is committed to improve the Customer Experiences by leveraging the power of AI with Snowflake Cortex.\n\nIn this tutorial, we will build a customer support agent that showcases the power of Cortex Fine-Tuning and helps the Tasty Bytes team to respond with a highly accurate automated email to customer tickets, all with minimal resources and time. Fine-tuning has significantly advanced the Tasty Bytes team's ability to meet the key objective which is nothing but enhancing customer experiences.\n\nWith Cortex Fine-Tuning, Snowflake users can harness the power of parameter-efficient fine-tuning (PEFT) to develop custom adaptors for specialized tasks using pre-trained models. This approach avoids the high cost of training a large model from scratch while achieving improved latency and performance compared to prompt engineering or retrieval-augmented generation (RAG) methods.\n\nWe will be using the Tasty Bytes customer support emails data for the purpose of this tutorial. When customers reach out to the Tasty Bytes support team over email, it is often found that there was partially missing information in the emails. The first interaction coming from the customer support agent in these cases will be a clarification question to get the missing information from the customer to provide a more tailored support. In order to increase the efficiency and reduce the operational overhead, automation can be achieved to respond based on the completeness of the email.\n\nFor example if there are required labels with missing values in the email, then an automated response can be sent to the customer asking for that information. In the case of the Tasty Bytes emails, city, truck or the menu item are values that an agent requires to process next steps for such cases."
  },
  {
   "cell_type": "markdown",
   "id": "63126ea2-b278-4305-90fb-39ac7a95d374",
   "metadata": {
    "name": "cell25",
    "collapsed": false
   },
   "source": "To begin, let's execute all the DDL statements and setup various database objects. We will be creating a separate role and implementing access control for ensuring privacy and security. Set the context.\n\n* Set the Role context to CFT_ROLE\n* Set the Warehouse context to CFT_WH\n* Set the Database context to CFT_DB\n* Set the schema CFT_SCHEMA"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "collapsed": false
   },
   "source": "CREATE OR REPLACE DATABASE CFT_DB;\n\nCREATE OR REPLACE SCHEMA CFT_DB.CFT_SCHEMA;\nCREATE OR REPLACE WAREHOUSE CFT_WH AUTO_SUSPEND = 60;\n-- create roles\nUSE ROLE securityadmin;\n\n-- functional roles\n\nCREATE ROLE IF NOT EXISTS CFT_ROLE COMMENT = 'Fine tuning role';\nGRANT ROLE CFT_ROLE TO role SYSADMIN;\nGRANT ALL ON WAREHOUSE CFT_WH TO ROLE CFT_ROLE;\n--Grants\nUSE ROLE securityadmin;\n\nGRANT USAGE ON DATABASE CFT_DB TO ROLE CFT_ROLE;\nGRANT USAGE ON ALL SCHEMAS IN DATABASE CFT_DB TO ROLE CFT_ROLE;\n\nGRANT ALL ON SCHEMA CFT_DB.CFT_SCHEMA TO ROLE CFT_ROLE;\n\nGRANT OWNERSHIP ON WAREHOUSE CFT_WH TO ROLE CFT_ROLE COPY CURRENT GRANTS;\n\n\n-- future grants\nGRANT ALL ON FUTURE TABLES IN SCHEMA CFT_DB.CFT_SCHEMA TO ROLE CFT_ROLE;\n/*--\n â€¢ File format and stage creation\n--*/\n\nUSE ROLE CFT_ROLE;\nUSE WAREHOUSE CFT_WH;\nUSE DATABASE CFT_DB;\nUSE SCHEMA CFT_SCHEMA;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "48983607-84a9-4a59-b205-c9c1920d8d5b",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE STAGE DATA_s3\nCOMMENT = 'CFT S3 Stage Connection'\nurl = 's3://sfquickstarts/frostbyte_tastybytes/fine_tuning/';\n\n--The Support emails and the various fields are added as a CSV. List and view the files in the Public S3 Bucket. \n\nLIST @CFT_DB.CFT_SCHEMA.DATA_s3;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1b11d795-f6fc-4bca-a7fb-31d98054435c",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "Once data has been added to a stage, let's create a table called SUPPORT_EMAILS for storing the raw emails from the customers. This dataset will be used in the next phase of data preparation.\n\n"
  },
  {
   "cell_type": "code",
   "id": "6b43c33c-4ce8-4e3e-be12-98486c1a17a2",
   "metadata": {
    "language": "sql",
    "name": "cell5"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE SUPPORT_EMAILS (        \n            ID INTEGER,\n            TIMESTAMP VARIANT,\n            SENDER VARCHAR,\n            SUBJECT VARCHAR,\n            BODY VARCHAR,  \n            LABELED_LOCATION VARCHAR,\n            LABELED_TRUCK VARCHAR,        \n            SUPPORT_RESPONSE VARCHAR\n            );\n            \n\n-- Load data from stage into table \nCOPY INTO SUPPORT_EMAILS\nFROM @CFT_DB.CFT_SCHEMA.DATA_s3/CFT_QUICKSTART.csv\nFILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY = '\"' SKIP_HEADER = 1);\n\n--Preview the data\nSELECT * FROM SUPPORT_EMAILS limit 20;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5735c3f4-4193-44ca-922b-96d814151ebb",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "The support emails contain a number of fields and we are more interested in required labels like truck and location, whether they are present or missing. If missing then the task for the LLM is to construct an email response that asks for clarification for the missing value. The goal of the data preparation step is to create a dataset that will be used to train the model and help it learn from the prompt/completion pairs and thus tune the LLM to make the automation agent parse and respond for future emails with right sense for missing and available annotations. \n\nThe FINETUNE function expects the training data to come from a Snowflake table or view and the query result must contain columns named prompt and completion. After loading the data into the SUPPORT_EMAILS table using the copy command with raw data with customer email and annotations. \n\nNext step would be to build a function to construct the \"completion\" which will be a JSON response on the raw data. The BUILD_EXAMPLE function will help for the above task. Now that the prompt and completion pairs are created, construct a training and a validation dataset from the base dataset. Using a Mod function on the Id field the Train and Test split can be built that will give a reproducible sample. Cortex Fine Tuning job needs only a small number of samples and by some experiments, it was already evaluated that a sample size of 128 was a good one."
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "source": "--Creation of a function to construct the Completion values, \nCREATE OR REPLACE FUNCTION BUILD_EXAMPLE(location STRING, truck STRING, response_body STRING)\nRETURNS STRING\nLANGUAGE SQL\nAS\n$$\nCONCAT(\n'{ location: ', IFF(location IS NULL, 'null', CONCAT('\"', location, '\"')), \n', truck: ', IFF(truck IS NULL, 'null', CONCAT('\"', truck, '\"')), \n', response_body: ', IFF(response_body IS NULL, 'null', CONCAT('\"', REPLACE(response_body, '\\n', '\\\\n'), '\"')), '\n}')\n$$\n;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1f446f82-0584-40fa-8868-973893341717",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE FINE_TUNING_TRAINING AS (\n    SELECT \n        *,\n        BUILD_EXAMPLE(\n            LABELED_LOCATION, LABELED_TRUCK, SUPPORT_RESPONSE\n        ) as GOLDEN_JSON\n    FROM SUPPORT_EMAILS\n    -- Split: 20% validation data, 80% training data\n    WHERE ID % 10 >= 2\n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2290ef90-e626-47f0-a721-cc9de61884a5",
   "metadata": {
    "language": "sql",
    "name": "cell26"
   },
   "outputs": [],
   "source": "SELECT * FROM FINE_TUNING_TRAINING LIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6022b17-2d1d-47cc-99d1-28130608273d",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE FINE_TUNING_VALIDATION AS (\n    SELECT \n        *,\n        BUILD_EXAMPLE(\n            LABELED_LOCATION, LABELED_TRUCK, SUPPORT_RESPONSE\n        ) as GOLDEN_JSON\n    FROM SUPPORT_EMAILS\n    -- Split: 20% validation data, 80% training data\n    WHERE ID % 10 < 2\n    \n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc4bd34c-71c2-465b-8c5e-6a450a78c1da",
   "metadata": {
    "language": "sql",
    "name": "cell23"
   },
   "outputs": [],
   "source": "select * from FINE_TUNING_VALIDATION limit 10;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1fc12b00-e29b-4c04-9224-3ea7d003947f",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "The following code calls the FINETUNE function and uses the SELECT ... AS syntax to set two of the columns in the query result to prompt and completion.\n\n## The following will probably take 3-5 minutes to run. It will run in the background.\n\nThe training data must come from a Snowflake table or view and the query result must contain columns named prompt and completion. If your table or view does not contain columns with the required names, use a column alias in your query to name them. This query is given as a parameter to the FINETUNE function. You will get an error if the results do not contain prompt and completion column names.\n\nA prompt is an input to the LLM and completion is the response from the LLM. Your training data should include prompt and completion pairs that show how you want the model to respond to particular prompts."
  },
  {
   "cell_type": "code",
   "id": "1a0bd614-7be3-4062-acac-5192b2ac15c1",
   "metadata": {
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": "-- STEP 3 :  Create a fine-tuning job \n-- Note to Brad - don't run this so you don't have to wait for it to finish.\n\n/*\nSELECT SNOWFLAKE.CORTEX.FINETUNE(\n    'CREATE', \n    -- Custom model name\n    'SUPPORT_MISTRAL_7B',\n    -- Base model name\n    'mistral-7b',\n    -- Training data query\n    'SELECT BODY AS PROMPT, GOLDEN_JSON AS COMPLETION FROM FINE_TUNING_TRAINING',\n    -- Validation data query \n    'SELECT BODY AS PROMPT, GOLDEN_JSON AS COMPLETION FROM FINE_TUNING_VALIDATION' \n);\n*/",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d4f82b31-c254-4dd7-bb5a-947e1c3dd79a",
   "metadata": {
    "name": "cell21",
    "collapsed": false
   },
   "source": "To describe the properties of a fine-tuning job. If the job completes successfully, additional details about the job are returned, including the final model name. Wait for about 5-10 minutes for the state to move to Completed."
  },
  {
   "cell_type": "code",
   "id": "940b4e0a-04cb-4b78-8e85-edd25a635965",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": "--Describe the properties of a fine-tuning job\nSelect SNOWFLAKE.CORTEX.FINETUNE(\n  'DESCRIBE',\n  'ft_a38f43a8-4466-4a5c-b4c6-c9f216cfb665'\n);\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "efc68381-e7b9-433a-877a-e288187d6f10",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "Once the Status turns to \"SUCCESS\" we will create a function to compute the accuracy of the returned outputs by the Fine Tuned model."
  },
  {
   "cell_type": "code",
   "id": "6bd570a1-d3e7-4d5d-a64e-fd77432de896",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": "--Describe the Models\n\nSHOW MODELS;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e76d4d73-7acb-417b-9dda-ca9ed4d6df93",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "The FINE_TUNING_VALIDATION_FINETUNED table contains the output by leveraging the Fine Tuned Model on the response body of the email. \n"
  },
  {
   "cell_type": "code",
   "id": "4659ba88-0f19-4b44-b991-4524f9090ce2",
   "metadata": {
    "language": "sql",
    "name": "cell11"
   },
   "outputs": [],
   "source": "--Create a table that stores the output computed using the function from Fine Tuned LLM \n\nCREATE OR REPLACE TABLE FINE_TUNING_VALIDATION_FINETUNED AS (\n    SELECT\n        -- Carry over fields from source for convenience.\n        ID, BODY, LABELED_TRUCK, LABELED_LOCATION,\n        -- Run the custom fine-tuned LLM.\n        SNOWFLAKE.CORTEX.COMPLETE(\n            -- Custom model\n            'SUPPORT_MISTRAL_7B', \n            body \n        ) AS RESPONSE\n    FROM FINE_TUNING_VALIDATION\n);\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9060db10-6b03-4d16-aeae-d39d8e16ed64",
   "metadata": {
    "language": "sql",
    "name": "cell12"
   },
   "outputs": [],
   "source": "-- STEP 4: Evaluate the Output\n\nSELECT B.BODY, TO_VARCHAR(GET_PATH(PARSE_JSON(A.RESPONSE), 'response_body')) AS LLM_RESPONSE, B.SUPPORT_RESPONSE AS CSR_RESPONSE, B.LABELED_TRUCK, B.LABELED_LOCATION\nFROM FINE_TUNING_VALIDATION_FINETUNED A\nINNER JOIN SUPPORT_EMAILS B\non A.id = B.id\nLIMIT 100;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b94adeb5-7aed-491f-b205-620ae10e8df6",
   "metadata": {
    "name": "cell18",
    "collapsed": false
   },
   "source": "### Cleanup\n\nRun the following cell if you'd like to cleanup\n\nSnowflake Cortex Fine-Tuning function incurs compute cost based on the number of tokens used in training. To get an estimate of the cost for the Fine Tuning job, refer to the consumption table for each cost in credits per million tokens. Also there are normal storage and warehouse costs applicable for storing the output customized adaptors, as well as for running any SQL commands."
  },
  {
   "cell_type": "code",
   "id": "c4f348de-872f-42fd-a642-df552f2b808b",
   "metadata": {
    "language": "sql",
    "name": "cell27"
   },
   "outputs": [],
   "source": "USE ROLE SYSADMIN;\nDROP DATABASE CFT_DB;\nDROP WAREHOUSE CFT_WH;\n\nUSE ROLE securityadmin;\nDROP ROLE CFT_ROLE;",
   "execution_count": null
  }
 ]
}