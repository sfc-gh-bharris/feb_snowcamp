{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "pb7qsvmbammauhptnxxk",
   "authorId": "1011012698186",
   "authorName": "BHARRIS",
   "authorEmail": "bradley.harris@snowflake.com",
   "sessionId": "e3d7e5d2-391d-4eb8-9474-7a59e60ce70c",
   "lastEditTime": 1738355434570
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "## From Kafka - in Snowpipe Streaming mode\nConfigure and install a new connector to load data in streaming mode:\n\nRun the following in your shell:\n\n```\nexport KAFKA_TOPIC=LIFT_TICKETS_KAFKA_STREAMING\neval $(cat .env)\n\nURL=\"https://$SNOWFLAKE_ACCOUNT.snowflakecomputing.com\"\nNAME=\"LIFT_TICKETS_KAFKA_STREAMING\"\n\ncurl -i -X PUT -H \"Content-Type:application/json\" \\\n    \"http://localhost:8083/connectors/$NAME/config\" \\\n    -d '{\n        \"connector.class\":\"com.snowflake.kafka.connector.SnowflakeSinkConnector\",\n        \"errors.log.enable\":\"true\",\n        \"snowflake.database.name\":\"INGEST\",\n        \"snowflake.private.key\":\"'$PRIVATE_KEY'\",\n        \"snowflake.schema.name\":\"INGEST\",\n        \"snowflake.role.name\":\"INGEST\",\n        \"snowflake.url.name\":\"'$URL'\",\n        \"snowflake.user.name\":\"'$SNOWFLAKE_USER'\",\n        \"snowflake.enable.schematization\": \"FALSE\",\n        \"snowflake.ingestion.method\": \"SNOWPIPE_STREAMING\",\n        \"topics\":\"'$KAFKA_TOPIC'\",\n        \"name\":\"'$NAME'\",\n        \"value.converter\":\"org.apache.kafka.connect.json.JsonConverter\",\n        \"value.converter.schemas.enable\":\"false\",\n        \"buffer.count.records\":\"1000000\",\n        \"buffer.flush.time\":\"10\",\n        \"buffer.size.bytes\":\"250000000\",\n        \"snowflake.topic2table.map\":\"'$KAFKA_TOPIC:LIFT_TICKETS_KAFKA_STREAMING'\"\n    }'\n\n```\n\nVerify the connector was created and is running in the [Redpanda console.](http://localhost:8080/topics)"
  },
  {
   "cell_type": "markdown",
   "id": "d4b50d9b-0f82-4684-9a4a-9a51cbe61d94",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "This configuration will allow data flowing through the connector to flush much quicker. The flush time is set to 10 seconds. Previously, it was often discussed how important file sizes were. That was because the files were directly impacting the efficient use of a warehouse. Streaming removes this complexity completely.\n\nData can be loaded in small pieces and will be merged together in the background efficiently by Snowflake. What is even better is that data is immediately available to query before it's merged. All use cases tested have shown Streaming to be as or MORE efficient than the previous Snowpipe only configuration.\n\nTo send in all your test data, you can run the following in your shell:\n\n```\nexport KAFKA_TOPIC=LIFT_TICKETS_KAFKA_STREAMING\ncat data.json.gz | zcat | python ./publish_data.py\n```"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "-- Query the table to verify the data was inserted. Data will appear in the table in a few seconds\nuse role ingest;\nuse database INGEST;\nuse schema INGEST;\n\nSELECT count(*) FROM LIFT_TICKETS_KAFKA_STREAMING;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "### Tips\n* Kafka Connector for Snowflake in Streaming mode is billed by the second of compute needed to merge files as well as the clients connected.\n* Setting the flush time lower can/will affect query performance as merge happens asynchronously.\n* Number of tasks, number of nodes in the Kafka Connect cluster, amount of CPU and memory on those nodes, and number of partitions will affect performance and credit consumption.\n* Streaming is the best ingest pattern when using Kafka."
  }
 ]
}