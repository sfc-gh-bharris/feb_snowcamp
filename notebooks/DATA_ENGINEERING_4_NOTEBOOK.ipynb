{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8a103a-f5ec-40fa-a720-bc930783dc6a",
   "metadata": {
    "collapsed": false,
    "name": "cell4"
   },
   "source": [
    "It's a common practice to use programming languages like Python in Data Engineering for constructing data pipelines. If you're migrating an existing data pipeline based on Python, Java, or Scala to Snowflake, Snowpark can be a valuable tool. Snowpark supports the creation of Python-based transformations through user-defined functions.\n",
    "\n",
    "In below example, we'll demonstrate how to build a cumulative total of customer account balances each month and leverage this information to identify any instances of customers exceeding their set limits in the CUST_INFO table. Let's create a new SQL worksheet and rename it to \"03_Dynamic_Table_With_UDTF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea5e1bb-2544-49f4-9d54-4b79a76ee185",
   "metadata": {
    "language": "sql",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "use database SNOW_DYNAMIC_TABLES_DE;\n",
    "use schema data;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a9757-5ecf-4072-84da-de823a2dc953",
   "metadata": {
    "collapsed": false,
    "name": "cell7"
   },
   "source": [
    "This function computes the cumulative total and can be seamlessly incorporated into any SQL code or applied to any table as a table function. It's flexibile and allows us to feed any data partition, making it highly adaptable to any \"cumulative total\" use case. Let's partition this total by Customer and Month using dynamic table. This way it becomes highly modular and SQL independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd72e1f-67cb-4062-bedc-447c48f91cfa",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION sum_table (INPUT_NUMBER number)\n",
    "  returns TABLE (running_total number)\n",
    "  language python\n",
    "  runtime_version = '3.8'\n",
    "  handler = 'gen_sum_table'\n",
    "as\n",
    "$$\n",
    "\n",
    "# Define handler class\n",
    "class gen_sum_table :\n",
    "\n",
    "  ## Define __init__ method ro initilize the variable\n",
    "  def __init__(self) :    \n",
    "    self._running_sum = 0\n",
    "  \n",
    "  ## Define process method\n",
    "  def process(self, input_number: float) :\n",
    "    # Increment running sum with data from the input row\n",
    "    new_total = self._running_sum + input_number\n",
    "    self._running_sum = new_total\n",
    "\n",
    "    yield(new_total,)\n",
    "  \n",
    "$$\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e14f5e-7c97-4636-b647-1d9ea1422174",
   "metadata": {
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE DYNAMIC TABLE cumulative_purchase\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE=DYNAMIC_TABLE_WH\n",
    "AS\n",
    "    select \n",
    "        month(creationtime) monthNum,\n",
    "        year(creationtime) yearNum,\n",
    "        customer_id, \n",
    "        saleprice,\n",
    "        running_total \n",
    "    from \n",
    "        salesreport,\n",
    "        table(sum_table(saleprice) over (partition by creationtime,customer_id order by creationtime, customer_id))\n",
    "       \n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408555b0-965e-4b54-a9bc-b2ad6e9ada63",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "select * from  cumulative_purchase limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f3e7dc-5bcd-46d9-95a3-736006b95217",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": [
    "Similar results can be achieved using complex SQL queries, but it becomes more versatile and modular when implemented as a Python User-Defined Function (UDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a34dd-1d26-4bfa-a5a1-569837d657ca",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": [
    "The DAG that we created above will build our data pipeline but there are many use cases of DT, like creating data validation checks or data quality etc. In our data set, we want to know if a product is running low on inventory, let's say less than 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3e63a-00b8-4330-a672-95a384b050b7",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE DYNAMIC TABLE PROD_INV_ALERT\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE=DYNAMIC_TABLE_WH\n",
    "AS\n",
    "    SELECT \n",
    "        S.PRODUCT_ID, \n",
    "        S.PRODUCT_NAME,CREATIONTIME AS LATEST_SALES_DATE,\n",
    "        STOCK AS BEGINING_STOCK,\n",
    "        SUM(S.QUANTITY) OVER (PARTITION BY S.PRODUCT_ID ORDER BY CREATIONTIME) TOTALUNITSOLD, \n",
    "        (STOCK - TOTALUNITSOLD) AS UNITSLEFT,\n",
    "        ROUND(((STOCK-TOTALUNITSOLD)/STOCK) *100,2) PERCENT_UNITLEFT,\n",
    "        CURRENT_TIMESTAMP() AS ROWCREATIONTIME\n",
    "    FROM SALESREPORT S JOIN PROD_STOCK_INV ON PRODUCT_ID = PID\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY PRODUCT_ID ORDER BY CREATIONTIME DESC) = 1\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed4f25-ea6b-49c0-a622-2924b705f746",
   "metadata": {
    "collapsed": false,
    "name": "cell3"
   },
   "source": [
    "Once this table has been built, we can now check and see if any products have low inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e70e95-bb70-4dcb-bd69-458bb0b6537b",
   "metadata": {
    "language": "sql",
    "name": "cell11"
   },
   "outputs": [],
   "source": [
    "select * from prod_inv_alert where percent_unitleft < 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41dad76-4081-4d15-ae6c-91d115421b7b",
   "metadata": {
    "collapsed": false,
    "name": "cell12"
   },
   "source": [
    "Alerts can help you send email alerts to your product procurement and inventory team to restock the required product. Remember to update the email address and warehouse in the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4ac23-57f3-48dc-9ba0-e1315e713a8c",
   "metadata": {
    "language": "sql",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "-- First we create an integration to send the emails.\n",
    "-- You can only send emails to an email address that has been verified in Snowflake. \n",
    "\n",
    "CREATE NOTIFICATION INTEGRATION IF NOT EXISTS\n",
    "    notification_emailer\n",
    "    TYPE=EMAIL\n",
    "    ENABLED=TRUE\n",
    "    ALLOWED_RECIPIENTS=('<YOUR_EMAIL>')\n",
    "    COMMENT = 'email integration to update on low product inventory levels';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61157171-b954-4acd-8a26-0bce8606e0c7",
   "metadata": {
    "collapsed": false,
    "name": "cell20"
   },
   "source": [
    "If you get an error that your email isn't valid or verified, you can click your initials in the bottom left, and go to 'my profile' to resent your verification email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f334ca4-aad0-4055-a6c5-27d75807a92f",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "-- Now we create the alert, using the integration we created above.\n",
    "\n",
    "CREATE OR REPLACE ALERT alert_low_inv\n",
    "  WAREHOUSE = DYNAMIC_TABLE_WH\n",
    "  SCHEDULE = '30 MINUTE'\n",
    "  IF (EXISTS (\n",
    "      SELECT *\n",
    "      FROM prod_inv_alert\n",
    "      WHERE percent_unitleft < 10 and ROWCREATIONTIME > SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME()\n",
    "  ))\n",
    "  THEN CALL SYSTEM$SEND_EMAIL(\n",
    "                'notification_emailer', -- notification integration to use\n",
    "                '<YOUR_EMAIL>', -- Email - be sure to update to yours\n",
    "                'Email Alert: Low Inventory of products', -- Subject\n",
    "                'Inventory running low for certain products. Please check the inventory report in Snowflake table prod_inv_alert' -- Body of email\n",
    ");\n",
    "\n",
    "-- Alerts are paused by default, so let's resume it first\n",
    "ALTER ALERT alert_low_inv RESUME;\n",
    "\n",
    "-- Add new records\n",
    "insert into salesdata select * from table(gen_cust_purchase(10000,2));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e558e-1267-4651-b0e8-1f3076a5f637",
   "metadata": {
    "collapsed": false,
    "name": "cell15"
   },
   "source": [
    "And within a minute or two, you should receive an email letting you know that there is low inventory.\n",
    "\n",
    "These alerts will only run if there is new data in the dynamic table (low inventory products). So, its easy to manage and maintain alerts in Snowflake on live data.\n",
    "\n",
    "You can monitor, resume or pause alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aba0ed-b649-4e77-b899-41dd25127840",
   "metadata": {
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "SHOW ALERTS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f80c8-7b07-45e7-a97e-acdd0cbbb6cd",
   "metadata": {
    "language": "sql",
    "name": "cell19"
   },
   "outputs": [],
   "source": [
    "-- If you would like, you can optionally force the alert to run.\n",
    "EXECUTE ALERT ALERT_LOW_INV;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463b923-6250-4c48-9821-afe14a876095",
   "metadata": {
    "language": "sql",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM\n",
    "  TABLE(INFORMATION_SCHEMA.ALERT_HISTORY(\n",
    "    SCHEDULED_TIME_RANGE_START\n",
    "      =>dateadd('hour',-1,current_timestamp())))\n",
    "WHERE\n",
    "    NAME = 'ALERT_LOW_INV'\n",
    "ORDER BY SCHEDULED_TIME DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2852d5-aeab-4eb4-9c6b-d4cd44423311",
   "metadata": {
    "language": "sql",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "\n",
    "-- Suspend Alerts \n",
    "-- Important step to suspend alert and stop consuming the warehouse credit\n",
    "ALTER ALERT alert_low_inv SUSPEND;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07db69fa-18b8-4597-99c9-c6e96ca2ad6a",
   "metadata": {
    "collapsed": false,
    "name": "cell22"
   },
   "source": [
    "Finally, Snowflake makes it easier to monitor your data pipeline.\n",
    "\n",
    "You can monitor Dynamic Tables using the DYNAMIC_TABLE_REFRESH_HISTORY() function in INFORMATION_SCHEMA. This is sample SQL for dynamic tables in our data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c661306-75b9-4307-8b96-c11b0d703961",
   "metadata": {
    "language": "sql",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "SELECT * \n",
    "FROM \n",
    "    TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY())\n",
    "WHERE \n",
    "    NAME IN ('SALESREPORT','CUSTOMER_SALES_DATA_HISTORY','PROD_INV_ALERT','CUMULATIVE_PURCHASE')\n",
    "    -- AND REFRESH_ACTION != 'NO_DATA'\n",
    "ORDER BY \n",
    "    DATA_TIMESTAMP DESC, REFRESH_END_TIME DESC LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b284c6-9eda-46b0-a392-b19d5d0c7179",
   "metadata": {
    "collapsed": false,
    "name": "cell23"
   },
   "source": [
    "You can use Snowsight GUI to visualize and monitor the directed acyclic graph (DAG) of your pipeline. Go to Data > Databases > DEMO > DT_DEMO > Dynamic Tables\n",
    "\n",
    "From Snowsight you can monitor Dynamic Table DAG, refresh history, preview data, refresh mode, columns and table ddl etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56d1be-6dff-4f68-9ee4-5a2db9747194",
   "metadata": {
    "collapsed": false,
    "name": "cell24"
   },
   "source": [
    "You can also monitor any issues with the refresh using the two table functions in information schema -\n",
    "\n",
    "[DYNAMIC_TABLE_REFRESH_HISTORY](https://docs.snowflake.com/en/sql-reference/functions/dynamic_table_refresh_history?_fsi=kVaBWUHz&_fsi=kVaBWUHz&_fsi=kVaBWUHz)\n",
    "\n",
    "[DYNAMIC_TABLE_GRAPH_HISTORY](https://docs.snowflake.com/en/sql-reference/functions/dynamic_table_graph_history?_fsi=kVaBWUHz&_fsi=kVaBWUHz&_fsi=kVaBWUHz)\n",
    "\n",
    "Few tips for monitoring Dynamic Tables -\n",
    "\n",
    "You should monitor Dynamic Tables for a few runs and verify if the refresh cycles are as desired (full or incremental).\n",
    "Consider that any changes to the base tables DDL will most certainly impact the performance or refresh cycles of the Dynamic tables just like any other data pipeline.\n",
    "In some cases DT defaults to full refresh like if you have masking policy on base tables, lateral flatten of nested structure or some other non deterministic functions like UDTF. These will be addressed in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4fe1d7-c6a0-49b6-828b-5bcda09c4444",
   "metadata": {
    "collapsed": false,
    "name": "cell25"
   },
   "source": [
    "SUSPEND and RESUME Dynamic Tables\n",
    "\n",
    "Dynamic tables can be suspended or resumed on demand. Snowflake automatically suspends it after 5 consecutive failures to prevent any credit consumption. If you suspend a Dynamic table upstream, it will automatically suspend its child or downstream Dynamic Tables in the DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc91a6a-5370-4548-8a8c-db0b9813f990",
   "metadata": {
    "language": "sql",
    "name": "cell26"
   },
   "outputs": [],
   "source": [
    "-- Resume the data pipeline\n",
    "alter dynamic table customer_sales_data_history RESUME;\n",
    "alter dynamic table salesreport RESUME;\n",
    "alter dynamic table prod_inv_alert RESUME;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2d0be-505a-4b12-b7d1-2db12be2b868",
   "metadata": {
    "language": "sql",
    "name": "cell28"
   },
   "outputs": [],
   "source": [
    "\n",
    "-- Suspend the data pipeline\n",
    "alter dynamic table customer_sales_data_history SUSPEND;\n",
    "alter dynamic table salesreport SUSPEND;\n",
    "alter dynamic table prod_inv_alert SUSPEND;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b2af9-5a90-459e-96d8-d34317974a83",
   "metadata": {
    "collapsed": false,
    "name": "cell27"
   },
   "source": [
    "Dynamic tables incur cost in three ways: [details here](https://docs.snowflake.com/en/user-guide/dynamic-tables-cost?_fsi=kVaBWUHz&_fsi=kVaBWUHz&_fsi=kVaBWUHz)\n",
    "\n",
    "* Storage: DT materializes the results and saves it just like a normal Snowflake tables\n",
    "* Cloud service compute: You will only incur this if daily cloud service cost is over 10% of your bill (very very rare)\n",
    "* Warehouse compute cost: this is associated with the warehouse you use with Dynamic Table. This is only used if there is data to be processed upstream from base tables\n",
    "\n",
    "\n",
    "Dynamic tables require a virtual warehouse to perform updates. Snowflake recommends testing dynamic tables using dedicated warehouses in order to understand related costs.Dynamic tables cost is driven by frequency of data refreshes in base tables and target LAG.\n",
    "\n",
    "REFRESH_MODE can be FULL or INCREMENTAL based on the query. You can run the Show Dynamic table command or check dynamic table dashboard to determine your DT refresh mode. Check [this page](https://docs.snowflake.com/en/user-guide/dynamic-tables-refresh?_fsi=kVaBWUHz&_fsi=kVaBWUHz&_fsi=kVaBWUHz#label-dynamic-tables-intro-refresh-queries) for more details.\n",
    "\n",
    "Dynamic tables support Time Travel, Replication, Data Governance, Masking, Tagging etc. just like a standard Snowflake table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "bradley.harris@snowflake.com",
   "authorId": "1011012698186",
   "authorName": "BHARRIS",
   "lastEditTime": 1738334150979,
   "notebookId": "muizevxqrebefhc66rma",
   "sessionId": "7537ab2a-9e2c-4be8-a0d3-110fbd763086"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
