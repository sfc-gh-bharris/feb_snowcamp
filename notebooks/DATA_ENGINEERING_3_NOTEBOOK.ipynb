{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "mulske2drsqhp6p55elu",
   "authorId": "1011012698186",
   "authorName": "BHARRIS",
   "authorEmail": "bradley.harris@snowflake.com",
   "sessionId": "5aaa9fe8-a3e0-4687-af6d-50e7c4d0e583",
   "lastEditTime": 1738280775812
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd5b356-77f7-4ead-8790-ddcbde09ce6e",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "With Dynamic Tables, customers provide a query and Snowflake automatically materializes the results of that query.\n\nThat means, instead of creating a separate target table and writing code to transform source data and update the data in that table, you can define the target table as a Dynamic Table, specifying the query that performs the transformation and just forget about the scheduling and orchestration.\n\nThe user specifies a minimum acceptable freshness in the result (target lag), and Snowflake automatically tries to meet that target, further enhancing the flexibility and control data engineers can have over their pipelines without the normally associated complexity.\n"
  },
  {
   "cell_type": "markdown",
   "id": "96f87b37-35e9-4925-b3a8-d93668ddbebc",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "For our first dynamic table we will extract the sales information from the salesdata table and join it with customer information to build the customer_sales_data_history, note that we are extracting raw json data(schema on read) and transforming it into meaningful columns and data type"
  },
  {
   "cell_type": "code",
   "id": "19559f26-1d91-4064-8780-f434582f0423",
   "metadata": {
    "language": "sql",
    "name": "cell5"
   },
   "outputs": [],
   "source": "use database SNOW_DYNAMIC_TABLES_DE;\nuse schema data;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "53ae316a-4b3d-4c12-8ad7-d2765b5fc086",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "For our dynamic tables, we need to specify a warehouse. \n\nDynamic tables require virtual warehouses to refresh - that is, run queries against base objects when they are initialized and refreshed, including both scheduled and manual refreshes. These operations use compute resources, which consume credits.\n\nWe're going to create a warehouse specifically for our dynamic tables"
  },
  {
   "cell_type": "code",
   "id": "26b350b8-f58c-43af-80f6-203a7f1312a4",
   "metadata": {
    "language": "sql",
    "name": "cell15"
   },
   "outputs": [],
   "source": "CREATE WAREHOUSE DYNAMIC_TABLE_WH\nWAREHOUSE_TYPE = STANDARD\n  WAREHOUSE_SIZE = XSMALL\n  AUTO_SUSPEND = 1;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "source": "CREATE OR REPLACE DYNAMIC TABLE customer_sales_data_history\n    LAG='DOWNSTREAM'\n    WAREHOUSE=DYNAMIC_TABLE_WH\nAS\nselect \n    s.custid as customer_id,\n    c.cname as customer_name,\n    s.purchase:\"prodid\"::number(5) as product_id,\n    s.purchase:\"purchase_amount\"::number(10) as saleprice,\n    s.purchase:\"quantity\"::number(5) as quantity,\n    s.purchase:\"purchase_date\"::date as salesdate\nfrom\n    cust_info c inner join salesdata s on c.custid = s.custid\n;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7f344077-9149-4deb-813d-b65551184f70",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "Dynamic table refresh is triggered based on how out of date the data might be, or what is commonly referred to as target lag. The target lag for a dynamic table is measured relative to the base tables at the root of the graph, not the dynamic tables directly upstream. Snowflake schedules refreshes to keep the actual lag of your dynamic tables below their target lag. The duration of each refresh depends on the query, data pattern, and warehouse size. When choosing a target lag, consider the time needed to refresh each dynamic table in a chain to the root. If you don’t, some refreshes might be skipped, leading to a higher actual lag.\n\nTo see the graph of tables connected to your dynamic table, see Use Snowsight to examine the graph of dynamic tables.\n\nTarget lag is specified in one of following ways:\n\n1) Measure of freshness: Defines the maximum amount of time that the dynamic table’s content should lag behind updates to the base tables.\n\n> The following example sets the product dynamic table to refresh and maintain freshness every hour:\n\n> ```ALTER DYNAMIC TABLE product SET TARGET_LAG = '1 hour';```\n\n2) Downstream: Specifies that the dynamic table should refresh on demand when other dependent dynamic tables refresh. This refresh can be triggered by a manual or scheduled refresh of a downstream dynamic table.\n\n> In the following example, product is based on other dynamic tables and is set to refresh based on the target lag of its downstream dynamic tables:\n\n> ```ALTER DYNAMIC TABLE product SET TARGET_LAG = DOWNSTREAM;```\n\nTarget lag is inversely proportional to the dynamic table’s refresh frequency: frequent refreshes imply a lower lag."
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "-- quick check\nselect * from customer_sales_data_history limit 10;\nselect count(*) from customer_sales_data_history;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "510fd0a4-605e-4f22-92f4-a5a761b060e0",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "Now, lets combine these results with the product table and create a transformation."
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "source": "CREATE OR REPLACE DYNAMIC TABLE salesreport\n    LAG = '1 MINUTE'\n    WAREHOUSE=DYNAMIC_TABLE_WH\nAS\n    Select\n        t1.customer_id,\n        t1.customer_name, \n        t1.product_id,\n        p.pname as product_name,\n        t1.saleprice,\n        t1.quantity,\n        (t1.saleprice/t1.quantity) as unitsalesprice,\n        t1.salesdate as CreationTime,\n        customer_id || '-' || t1.product_id  || '-' || t1.salesdate AS CUSTOMER_SK,\n        LEAD(CreationTime) OVER (PARTITION BY t1.customer_id ORDER BY CreationTime ASC) AS END_TIME\n    from \n        customer_sales_data_history t1 inner join prod_stock_inv p \n        on t1.product_id = p.pid\n       \n;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c50b0027-60a3-48e4-94db-7aaf20b74a35",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": "-- Another quick check\nselect * from salesreport limit 10;\nselect count(*) from salesreport;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b2693e5c-648c-4cd5-bf96-86ce218d8123",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "Let's test this DAG by adding some raw data in the base tables."
  },
  {
   "cell_type": "code",
   "id": "358df66b-a672-49bc-838f-43d4bc6c429f",
   "metadata": {
    "language": "sql",
    "name": "cell12"
   },
   "outputs": [],
   "source": "-- Add new records\ninsert into salesdata select * from table(gen_cust_purchase(10000,2));\n\n-- Check raw base table\nselect count(*) from salesdata;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b4204328-d65c-482b-9985-87f2f4329af6",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": "\n-- Check Dynamic Tables after a minute\nselect count(*) from customer_sales_data_history;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa3a5c6b-36ae-4aa2-86d4-62385a9b4597",
   "metadata": {
    "name": "cell14",
    "collapsed": false
   },
   "source": "While we're waiting, lets open a new window and check the dynamic table graph and refresh history in Snowsight."
  },
  {
   "cell_type": "markdown",
   "id": "1c204444-9066-4d66-9d71-50cb9d7fcca6",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "That's it, we created a DAG using Dynamic Tables. It runs whenever there is data in the raw base tables and infers the lag based on the downstream dynamic tables lag using the LAG parameter as \"DOWNSTREAM\". In this example the CUSTOMER_SALES_DATA_HISTORY table will refresh based on the lag of its downstream table (\"1 Minute\") and data in the raw table (SALESDATA)."
  }
 ]
}