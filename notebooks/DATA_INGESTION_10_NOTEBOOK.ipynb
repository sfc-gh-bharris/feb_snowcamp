{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "kocnpizfhn2x572yqw6g",
   "authorId": "1011012698186",
   "authorName": "BHARRIS",
   "authorEmail": "bradley.harris@snowflake.com",
   "sessionId": "2bcbb7a0-545a-4781-a99e-b39d2959075b",
   "lastEditTime": 1738355625171
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "## From Kafka - Streaming with Schematization\nThe previous methods for loading data from Kafka landed the data in a Variant field. While this is flexible, it is not the most user friendly or performant way to land data. The Snowflake Connector for Kafka can use schematization to maintain the schema of the landed data.\n\nConfigure and install a new connector to load data in streaming mode WITH schematization:\n\nRun the following in your shell:\n\n```\nexport KAFKA_TOPIC=LIFT_TICKETS_KAFKA_STREAMING_SCHEMATIZED\neval $(cat .env)\n\nURL=\"https://$SNOWFLAKE_ACCOUNT.snowflakecomputing.com\"\nNAME=\"LIFT_TICKETS_KAFKA_STREAMING_SCHEMATIZED\"\n\ncurl -i -X PUT -H \"Content-Type:application/json\" \\\n    \"http://localhost:8083/connectors/$NAME/config\" \\\n    -d '{\n        \"connector.class\":\"com.snowflake.kafka.connector.SnowflakeSinkConnector\",\n        \"errors.log.enable\":\"true\",\n        \"snowflake.database.name\":\"INGEST\",\n        \"snowflake.private.key\":\"'$PRIVATE_KEY'\",\n        \"snowflake.schema.name\":\"INGEST\",\n        \"snowflake.role.name\":\"INGEST\",\n        \"snowflake.url.name\":\"'$URL'\",\n        \"snowflake.user.name\":\"'$SNOWFLAKE_USER'\",\n        \"snowflake.enable.schematization\": \"TRUE\",\n        \"snowflake.ingestion.method\": \"SNOWPIPE_STREAMING\",\n        \"topics\":\"'$KAFKA_TOPIC'\",\n        \"name\":\"'$NAME'\",\n        \"value.converter\":\"org.apache.kafka.connect.json.JsonConverter\",\n        \"value.converter.schemas.enable\":\"false\",\n        \"buffer.count.records\":\"1000000\",\n        \"buffer.flush.time\":\"10\",\n        \"buffer.size.bytes\":\"250000000\",\n        \"snowflake.topic2table.map\":\"'$KAFKA_TOPIC:LIFT_TICKETS_KAFKA_STREAMING_SCHEMATIZED'\"\n    }'\n```\n\nVerify the connector was created and is running in the Redpanda console.\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "022f0753-01a6-4479-95c7-66cc2fe5aa74",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "To send in all your test data, you can run the following in your shell:\n\n```\nexport KAFKA_TOPIC=LIFT_TICKETS_KAFKA_STREAMING_SCHEMATIZED\ncat data.json.gz | zcat | python ./publish_data.py\n```"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "-- The data will land in a table the Connector creates with the schema based on the payload. To see the table and data, run the following SQL:\nUSE ROLE INGEST;\nUSE DATABASE INGEST;\nUSE SCHEMA INGEST;\n\nSELECT * FROM LIFT_TICKETS_KAFKA_STREAMING_SCHEMATIZED limit 100;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5fab4b02-d52b-4b22-8e86-d16ad07cd0ea",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "outputs": [],
   "source": "-- compared to our previous run\nSELECT * FROM LIFT_TICKETS_KAFKA_STREAMING limit 100;",
   "execution_count": null
  }
 ]
}